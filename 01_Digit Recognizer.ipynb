{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 9: Handwritten digit recognition using a Gaussian Generative Model\n",
    "\n",
    "The solution has the following parts:\n",
    "\n",
    "1. Load the data\n",
    "2. Prepare the data by splitting the train data into training set and validation set\n",
    "3. Create a classifier routine using multinomial_normal function\n",
    "4. Iterate over several smoothing factor to land at the best smoothing factor on the validation set\n",
    "5. Apply the best smoothing factor on the test data set and calculate the accuracy\n",
    "6. Display a few misclassified digits and their posterior probabilities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/Deepthi/Documents/Personal/Kaggle/01_Digit Recognizer/Data\n"
     ]
    }
   ],
   "source": [
    "%cd /Users/Deepthi/Documents/Personal/Kaggle/01_Digit Recognizer/Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import the required libraries\n",
    "from struct import unpack\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "from sklearn.cross_validation import train_test_split;\n",
    "import math \n",
    "from scipy.stats import multivariate_normal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from numpy import genfromtxt\n",
    "train_data = genfromtxt('train.csv', delimiter=',')\n",
    "test_data = genfromtxt('test.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_labels = np.ravel(train_data[1:,:1])\n",
    "train_images = train_data[1:,1:785]\n",
    "test_images = test_data[1:,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the data by splitting the train data into training set and validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Split the train data into train and validation sets\n",
    "train_set,validation_set, train_label, validation_label = train_test_split(train_images,train_labels, test_size=10000, random_state=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a classifier routine using multinomial_normal function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a function to determine the clas probabilities, calculate mean and cov and fit a gaussian\n",
    "def classifier(c,data_set,label_set):\n",
    "    label = []\n",
    "    pd = []\n",
    "    for i in range(0,10):\n",
    "        priors = len(train_set[np.where(train_label==i)])/float(len(train_set))\n",
    "        Mean = train_set[np.where(train_label==i)].mean(0)\n",
    "        Cov = np.cov((train_set[np.where(train_label==i)]).T)\n",
    "        Cov = Cov + (c*np.identity(784))\n",
    "        px = multivariate_normal(mean=Mean, cov=Cov) \n",
    "        pd.append(np.log(priors) + px.logpdf(data_set))\n",
    "    max_prob = np.argmax(pd, axis = 0)\n",
    "    error = np.sum([i!=j for i,j in zip(max_prob, label_set)])*100/(len(label_set)*1.0)\n",
    "    accuracy = 100- (np.sum([i!=j for i,j in zip(max_prob, label_set)])*100/(len(label_set)*1.0))\n",
    "    return c, error, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32000, 784)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32000,)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.,  7.,  2., ...,  2.,  9.,  2.])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.ravel(train_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterate over several smoothing factor to land at the best smoothing factor on the validation set\n",
    "\n",
    "To obtain optimum smoothing factor:\n",
    "\n",
    "1. First try in steps of 1000 to determine the most optimum zone (The zone in which you achieve best accuracy)\n",
    "2. Repeat the same in steps of 100, 10 and then 1 to land on the most optimum smoothing value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 5.3700000000000001, 94.629999999999995)\n",
      "(2000, 4.8099999999999996, 95.189999999999998)\n",
      "(3000, 4.7300000000000004, 95.269999999999996)\n",
      "(4000, 4.7800000000000002, 95.219999999999999)\n",
      "(5000, 4.8200000000000003, 95.180000000000007)\n",
      "(6000, 4.9699999999999998, 95.030000000000001)\n",
      "(7000, 5.1900000000000004, 94.810000000000002)\n",
      "(8000, 5.3600000000000003, 94.640000000000001)\n",
      "(9000, 5.4500000000000002, 94.549999999999997)\n",
      "(10000, 5.5300000000000002, 94.469999999999999)\n",
      "(11000, 5.7000000000000002, 94.299999999999997)\n",
      "(12000, 5.8200000000000003, 94.180000000000007)\n",
      "(13000, 5.9000000000000004, 94.099999999999994)\n",
      "(14000, 6.0499999999999998, 93.950000000000003)\n"
     ]
    }
   ],
   "source": [
    "# Go in steps of 1000 from 1000 to 15000:\n",
    "for c in np.arange(1000,15000,1000):\n",
    "    print classifier(c,validation_set, validation_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Consider 2000 to 4000 in steps of 100\n",
    "for c in np.arange(2000,4000,100):\n",
    "    print classifier(c,validation_set, validation_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Consider 2500 to 2700 in steps of 10\n",
    "for c in np.arange(2500,2700,10):\n",
    "    print classifier(c,validation_set, validation_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Consider 2610 to 2640 in steps of 1\n",
    "for c in np.arange(2610,2640,1):\n",
    "    print classifier(c,validation_set, validation_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Test the the optimum smoothing value on validation set\n",
    "print classifier(2613,validation_set, validation_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply the best smoothing factor on the test data set and calculate the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Apply the classifier on the test data to understand the accuracy\n",
    "\n",
    "def classifiertest(c,data_set):\n",
    "    label = []\n",
    "    pd = []\n",
    "    for i in range(0,10):\n",
    "        priors = len(train_images[np.where(train_labels==i)])/float(len(train_set))\n",
    "        Mean = train_images[np.where(train_labels==i)].mean(0)\n",
    "        Cov = np.cov((train_images[np.where(train_labels==i)]).T)\n",
    "        Cov = Cov + (c*np.identity(784))\n",
    "        px = multivariate_normal(mean=Mean, cov=Cov) \n",
    "        pd.append(np.log(priors) + px.logpdf(data_set))\n",
    "    max_prob = np.argmax(pd, axis = 0)\n",
    "    return max_prob\n",
    "\n",
    "\n",
    "testoutput = classifiertest(2613,test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testoutput = [int(x) for x in testoutput]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(testoutput)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.to_csv('final_output_2', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
